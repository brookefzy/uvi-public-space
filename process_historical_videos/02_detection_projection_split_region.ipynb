{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "def imshow(image, show_axes = False, quiet = False):\n",
    "    if len(image.shape) == 3:\n",
    "      # Height, width, channels\n",
    "      # Assume BGR, do a conversion since \n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "      # Height, width - must be grayscale\n",
    "      # convert to RGB, since matplotlib will plot in a weird colormap (instead of black = 0, white = 1)\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    # Draw the image\n",
    "    plt.imshow(image)\n",
    "    if not show_axes:\n",
    "        # We'll also disable drawing the axes and tick marks in the plot, since it's actually an image\n",
    "        plt.axis('off')\n",
    "    if not quiet:\n",
    "        # Make sure it outputs\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_matrix(ref):\n",
    "    '''\n",
    "\n",
    "    pts_src and pts_dst are numpy arrays of points\n",
    "\n",
    "    in source and destination images. We need at least\n",
    "\n",
    "    corresponding points.\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        pts_src = np.array([(x,y) for x,y in zip(ref['sourceX'], -1*ref['sourceY'])])\n",
    "    except:\n",
    "        pts_src = np.array([(x,y) for x,y in zip(ref['pixelX'], -1*ref['pixelY'])])\n",
    "\n",
    "    pts_dst  = np.array([(x,y) for x,y in zip(ref['mapX'], ref['mapY'])])\n",
    "\n",
    "    h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "    '''\n",
    "    The calculated homography can be used to warp\n",
    "\n",
    "    the source image to destination. Size is the\n",
    "\n",
    "    size (width,height) of im_dst\n",
    "    '''\n",
    "    return h\n",
    "\n",
    "def projectPlan(df, h, x, y):\n",
    "    pts = df[[x, y]].values\n",
    "    ## (n, 1, 2)\n",
    "    pts1 = pts.reshape(-1,1,2).astype(np.float32)\n",
    "    dst1 = cv2.perspectiveTransform(pts1, h)\n",
    "    return dst1\n",
    "\n",
    "\n",
    "def pixel2coord(col, row, ds):\n",
    "    # 3. transform to 2326 geolocation\n",
    "    c, a, b, f, d, e = ds.GetGeoTransform()\n",
    "    \"\"\"Returns global coordinates to pixel center using base-0 raster index\"\"\"\n",
    "    xp = a * col + b * row + a * 0.5 + b * 0.5 + c\n",
    "    yp = d * col + e * row + d * 0.5 + e * 0.5 + f\n",
    "    return(xp, yp)\n",
    "\n",
    "\n",
    "# bbox0, bbox1, bbox2, bbox3 : x1, y1, w, h\n",
    "# Replace this part for other data\n",
    "# Trace\n",
    "\n",
    "# check gender distribution within one track_id\n",
    "# set attribute list\n",
    "def get_attr(trace):\n",
    "    attribute_ls = ['gender', 'age', 'side', 'glasses', 'hat', 'hold_objects_in_front',\n",
    "        'bag', 'upper', 'lower', 'boots']\n",
    "    # for each track_id only keep one major attribute\n",
    "    for attr in attribute_ls:\n",
    "        trace[attr] = trace.groupby(\"track_id\")[attr].transform(lambda x: x.mode()[0])\n",
    "    trace[trace[\"track_id\"] == 1].groupby([\"gender\"]).size()\n",
    "\n",
    "    attr_df = trace.drop_duplicates(\"track_id\")[attribute_ls+[\"track_id\"]]\n",
    "    return attr_df\n",
    "\n",
    "def getclean(trace, h, epsg, videoname):\n",
    "\n",
    "    trace['loc_x'] = (trace['bbox0'] + trace['bbox0'] + trace['bbox2'])/2\n",
    "    trace['loc_y'] = (trace['bbox1'] + trace['bbox3'])\n",
    "    \n",
    "    trs2 = projectPlan(trace, h, 'loc_x', 'loc_y')\n",
    "    trace[f'x_{epsg}'] = trs2[:,:,0]\n",
    "    trace[f'y_{epsg}'] = trs2[:,:,1] \n",
    "    \n",
    "    trace['video_id'] = videoname\n",
    "    \n",
    "    cols = ['video_id',\n",
    "        'frame_id',\n",
    "                  'track_id','loc_x', 'loc_y',\n",
    "                     f'x_{epsg}', f'y_{epsg}', # reference geo in HK\n",
    "                     'category_id',\n",
    "                     \"score\"\n",
    "                  ]\n",
    "    cols_keep = [x for x in trace.columns if x in cols]\n",
    "    return trace[cols_keep]\n",
    "            \n",
    "\n",
    "def getgdf(traceDF, epsg, tail = True, length = 3):\n",
    "    \"\"\"length: refers to the second of lagging tail we want to see\"\"\"\n",
    "    # smoothe the x, y for every 30 frames\n",
    "    # do not do smooth for historical video given the potential miss tracking\n",
    "    # traceDF['moving_x'] = traceDF.groupby('track_id')[f'x_{epsg}'].transform(lambda x: x.rolling(30, 1).mean())\n",
    "    # traceDF['moving_y'] = traceDF.groupby('track_id')[f'y_{epsg}'].transform(lambda x: x.rolling(30, 1).mean())\n",
    "\n",
    "    traceGDF = gpd.GeoDataFrame(traceDF, geometry = [Point(x,y) for x,y in zip(traceDF[f'x_{epsg}'],traceDF[f'y_{epsg}'])])\n",
    "    traceGDF.crs = f\"EPSG:{epsg}\"\n",
    "    traceGDF = traceGDF.to_crs('EPSG:4326')\n",
    "    traceGDF['lat'] = traceGDF['geometry'].y\n",
    "    traceGDF['lon'] = traceGDF['geometry'].x\n",
    "    return traceGDF\n",
    "\n",
    "# drop the outlier automatically\n",
    "def find_outliers_IQR(df, field, low = 0.25, high = 0.75):\n",
    "\n",
    "   q1=df[field].quantile(low)\n",
    "\n",
    "   q3=df[field].quantile(high)\n",
    "\n",
    "   IQR=q3-q1\n",
    "\n",
    "   outliers = df[((df[field]<(q1-1.5*IQR)) | (df[field]>(q3+1.5*IQR)))]\n",
    "\n",
    "   keep = df[((df[field]>=(q1-1.5*IQR)) & (df[field]<=(q3+1.5*IQR)))].reset_index(drop = True)\n",
    "\n",
    "   return outliers, keep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_video(sample_id, ref, videopath):\n",
    "    \"\"\"This algorithm is different from dealing the new video\"\"\"\n",
    "    # ref_path = videopath[videopath['video_id'] == sample_id]['ref_path'].values[0]\n",
    "    pred_path = videopath[videopath['video_id'] == sample_id]['pred_path'].values[0]\n",
    "    epsg = videopath[videopath['video_id'] == sample_id]['ref_epsg'].values[0]\n",
    "    # ref = get_ref(ref_path)\n",
    "    trace = pd.read_csv(pred_path, sep = '\\t', header = None)\n",
    "    trace.columns = [ \"x1\", \"y1\", \"x2\", \"y2\", \"track_id\", \"frame_id\"]\n",
    "    trace['w'] = trace['x2'] - trace['x1']\n",
    "    trace['h'] = trace['y2'] - trace['y1']\n",
    "    trace['ratio'] = trace['w']/trace['h']\n",
    "    _, trace = find_outliers_IQR(trace, 'ratio', 0.15, 0.85)\n",
    "    trace.rename(columns = {\"x1\":\"bbox0\", \"y1\":\"bbox1\", \"w\":\"bbox2\", \"h\":\"bbox3\"}, inplace = True)\n",
    "    h = get_proj_matrix(ref)\n",
    "    traceDF = getclean(trace, h, epsg, sample_id)\n",
    "    traceGDF = getgdf(traceDF, epsg)\n",
    "    _, traceGDF_keep = find_outliers_IQR(traceGDF, \n",
    "                                         f'x_{epsg}')\n",
    "    return traceGDF\n",
    "\n",
    "def getbasics(file_path):\n",
    "    video = cv2.VideoCapture(file_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('frames per second =',fps)\n",
    "    size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    print('frames size =',size)\n",
    "    # video.release()\n",
    "    return video, fps, size, length\n",
    "\n",
    "# read in the points\n",
    "def get_ref(ref_path):\n",
    "    # with open(ref_folder + ref_video + f\"_3446_modified.tif.points\", \"r\") as f:\n",
    "    with open(ref_path, \"r\", \n",
    "              encoding = 'utf-8', \n",
    "              errors = 'ignore') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip().split(\",\") for line in lines]\n",
    "    # convert to dataframe\n",
    "    ref = pd.DataFrame(lines[2:], columns = lines[1])\n",
    "    # convert to float\n",
    "    ref = ref.astype(float)\n",
    "    return ref\n",
    "\n",
    "\n",
    "def get_all_info(videopath_sel, videoname, useimage = True):\n",
    "\n",
    "    ref_path = videopath_sel[videopath_sel['video_id']==videoname]['ref_path'].values[0]\n",
    "    ref = get_ref(ref_path)\n",
    "    traceGDF_keep = get_proj_video(videoname, ref)\n",
    "    if \"category_id\" in traceGDF_keep.columns:\n",
    "        traceGDF_people = traceGDF_keep[(traceGDF_keep[\"category_id\"] == 0)&(traceGDF_keep[\"score\"]>0.1)].reset_index(drop = True)\n",
    "        return traceGDF_people\n",
    "    else:\n",
    "        return traceGDF_keep\n",
    "    \n",
    "def get_frame_num(time_str, fps = 29.97002997002997):\n",
    "    try:\n",
    "        time = time_str.split(\" \")[0][3:].split(\":\")\n",
    "        minute = int(time[0])\n",
    "        second = int(time[1])\n",
    "        frame = minute*60*fps + second*fps\n",
    "        return int(frame)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "enlarged_video = \"../../_data/08_historical_valid_scene/video_enlarged\"\n",
    "txt_folder = \"../../_data/03_tracking_result/_old_videos/yolo5_deepsort\"\n",
    "frame_folder = \"../../_data/08_historical_valid_scene/Frames\"\n",
    "points_folder = \"../../_data/08_historical_valid_scene/Frames\"\n",
    "predictionls = glob(os.path.join(txt_folder, \"*.txt\"))\n",
    "pointsls = glob(os.path.join(points_folder, \"*.points\"))\n",
    "videos = glob(os.path.join(enlarged_video, \"*.mp4\"))\n",
    "\n",
    "videos_ls = [os.path.basename(x).split(\".\")[0] for x in videos]\n",
    "videols = [os.path.basename(x).split(\".\")[0] for x in predictionls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcloudapi = \"AIzaSyCohhLdvyTC0UsGriQ9j-rU8pRln5wVVG8\"\n",
    "serviceaccount = \"/Users/yuan/Dropbox (Personal)/personal files/ssh/google_drive_personal.json\"\n",
    "import gspread\n",
    "# from oauth2client.service_account import ServiceAccountCredentials\n",
    "gc = gspread.service_account(filename = serviceaccount)\n",
    "\n",
    "\n",
    "def read_url(url, SHEET_NAME):\n",
    "    SHEET_ID = url.split('/')[5]\n",
    "    spreadsheet = gc.open_by_key(SHEET_ID)\n",
    "    worksheet = spreadsheet.worksheet(SHEET_NAME)\n",
    "    rows = worksheet.get_all_records()\n",
    "    df_spread = pd.DataFrame(rows)\n",
    "    return df_spread, worksheet\n",
    "\n",
    "url = \"https://docs.google.com/spreadsheets/d/1djLf9Uhh1zJpPBiSyjTnZ_EkkP1uZf2L8Rg8XWmXKlY/edit?usp=sharing\"\n",
    "SHEETNAME = \"P1_historical_videos\"\n",
    "video_df, other_worksheet = read_url( url, SHEETNAME)\n",
    "# video_meta['video_id'] = video_meta['video_id'].apply(lambda x: x.split(\"-Scene\")[0])\n",
    "video_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample image\n",
    "# sample_id = 'B10_G2_Env5_0001-Scene-006'\n",
    "\n",
    "framefolder = \"../../_data/08_historical_valid_scene/frames_selected/\"\n",
    "def save_img(sample_id, ptls, framefolder = framefolder):\n",
    "    thickness = 2\n",
    "    color = (255, 0, 0)\n",
    "    isClosed = True\n",
    "    imgpath = os.path.join(framefolder, sample_id +\".jpg\")\n",
    "    # image  = cv2.cvtColor(cv2.imread(imgpath), cv2.COLOR_BGR2RGB)\n",
    "    for pts in ptls:\n",
    "        pts = pts.reshape((-1, 1, 2))\n",
    "        image = cv2.polylines(image, [pts],\n",
    "                        isClosed, color, thickness)\n",
    "    # ptls = [list(x) for x in ptls]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10,10))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    cv2.imwrite(os.path.join(framefolder, sample_id+\"split.jpg\"), image)\n",
    "\n",
    "    ptdict = {\n",
    "        \"g\":ptls[0],\n",
    "        \"r\":ptls[1],\n",
    "        \"l\":ptls[2],\n",
    "        \"t\":ptls[3]\n",
    "    }\n",
    "    regiondf = gpd.GeoDataFrame({\n",
    "        \"region\":list(ptdict.keys()),\n",
    "        \"geometry\":[Polygon([(x,y) for x,y in pts]) for pts in ptdict.values()]\n",
    "    }, geometry=\"geometry\")\n",
    "    regiondf.plot()\n",
    "    regiondf.to_file(os.path.join(framefolder, sample_id+\"_split_region.geojson\"), driver = \"GeoJSON\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = \"B10_G2_Env3_0001\"\n",
    "\n",
    "pa = [460, 295]\n",
    "pb = [660, 220]\n",
    "pc = [430,145]\n",
    "pd = [0, 160]\n",
    "\n",
    "\n",
    "pts1 = np.array([pa, pb, [720, 250],[720,480], [0, 480], pd],\n",
    "               np.int32) \n",
    "pts2 = np.array([pa, pc, [500, 135],pb],\n",
    "               np.int32)\n",
    "pts3 = np.array([pa, pc, [150,100],[0, 120],pd],\n",
    "               np.int32)\n",
    "pts4 = np.array([pc, [500, 135],  [260,95], [150,100]],\n",
    "               np.int32)\n",
    "ptls = [\n",
    "    pts1, # ground\n",
    "        pts2, # right\n",
    "        pts3, # left\n",
    "        pts4 # top\n",
    "        ]\n",
    "save_img(sample_id, ptls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = \"B10_G2_Env4_0001\"\n",
    "\n",
    "pa = [460, 300]\n",
    "pb = [660, 230]\n",
    "pc = [430,150]\n",
    "\n",
    "\n",
    "pts1 = np.array([pa, pb, [720, 250],[720,480], [0, 480], [0, 170]],\n",
    "               np.int32) \n",
    "pts2 = np.array([pa, pc, [500, 135],pb],\n",
    "               np.int32)\n",
    "pts3 = np.array([pa, pc, [150,100],[0, 120],[0, 170]],\n",
    "               np.int32)\n",
    "pts4 = np.array([pc, [500, 135],  [260,95], [150,100]],\n",
    "               np.int32)\n",
    "ptls = [\n",
    "    pts1, # ground\n",
    "        pts2, # right\n",
    "        pts3, # left\n",
    "        pts4 # top\n",
    "        ]\n",
    "save_img(sample_id, ptls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 'B10_G2_Env5_0001-Scene-006'\n",
    "\n",
    "image  = cv2.cvtColor(cv2.imread(imgpath), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "pts1 = np.array([[450, 305], [650,230], [720, 250],[720,480], [0, 480], [0, 170]],\n",
    "               np.int32) \n",
    "pts2 = np.array([[450, 305], [420,150], [500, 135],[650,230]],\n",
    "               np.int32)\n",
    "pts3 = np.array([[450, 305], [420,150], [150,100],[0, 120],[0, 170]],\n",
    "               np.int32)\n",
    "pts4 = np.array([[420,150], [500, 135],  [250,100], [150,100]],\n",
    "               np.int32)\n",
    "ptls = [\n",
    "    pts1, # ground\n",
    "        pts2, # right\n",
    "        pts3, # left\n",
    "        pts4 # top\n",
    "        ]\n",
    "save_img(sample_id, ptls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_folder = \"../../_data/08_historical_valid_scene/Frames/\"\n",
    "refs = glob(os.path.join(ref_folder, \"*.points\"))\n",
    "refs = [x for x in refs if sample_id in x]\n",
    "ref_dict = dict(zip(\n",
    "    [\"t\",\"g\", \"l\", \"r\"],\n",
    "    refs\n",
    "))\n",
    "ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regiondf = gpd.GeoDataFrame({\n",
    "    \"region\":list(ptdict.keys()),\n",
    "    \"geometry\":[Polygon([(x,y) for x,y in pts]) for pts in ptdict.values()]\n",
    "}, geometry=\"geometry\")\n",
    "regiondf.plot()\n",
    "regiondf.to_file(os.path.join(frame_folder, sample_id+\"_split_region.geojson\"), driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = videopath[videopath['video_id'] == sample_id]['pred_path'].values[0]\n",
    "epsg = videopath[videopath['video_id'] == sample_id]['ref_epsg'].values[0]\n",
    "# ref = get_ref(ref_path)\n",
    "trace = pd.read_csv(pred_path, sep = '\\t', header = None)\n",
    "trace.columns = [ \"x1\", \"y1\", \"x2\", \"y2\", \"track_id\", \"frame_id\"]\n",
    "trace['w'] = trace['x2'] - trace['x1']\n",
    "trace['h'] = trace['y2'] - trace['y1']\n",
    "trace['ratio'] = trace['w']/trace['h']\n",
    "_, trace = find_outliers_IQR(trace, 'ratio', 0.15, 0.85)\n",
    "trace.rename(columns = {\"x1\":\"bbox0\", \"y1\":\"bbox1\", \"w\":\"bbox2\", \"h\":\"bbox3\"}, inplace = True)\n",
    "\n",
    "trace['loc_x'] = (trace['bbox0'] + trace['bbox0'] + trace['bbox2'])/2\n",
    "trace['loc_y'] = (trace['bbox1'] + trace['bbox3'])\n",
    "tracept = gpd.GeoDataFrame(\n",
    "    trace,\n",
    "    geometry = gpd.points_from_xy(trace.loc_x, trace.loc_y)\n",
    ")\n",
    "# spatial join to get region name\n",
    "tracept_update = gpd.sjoin(tracept, regiondf, how = 'inner') # regiondf currently is a global variable. needs to be updated to match different view angle\n",
    "print(\"region assigned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceGDF_all = []\n",
    "for r in ref_dict.keys():\n",
    "    ref = get_ref(ref_dict[r])\n",
    "    h = get_proj_matrix(ref)\n",
    "\n",
    "    trace_sel = tracept_update[tracept_update['region'] == r]\n",
    "    traceDF = getclean(trace_sel, h, epsg, sample_id)\n",
    "\n",
    "    traceGDF = getgdf(traceDF, epsg)\n",
    "    _, traceGDF_keep = find_outliers_IQR(traceGDF, \n",
    "                                            f'x_{epsg}')\n",
    "    traceGDF_all.append(traceGDF_keep)\n",
    "traceGDF_keep = pd.concat(traceGDF_all).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceGDF_keep['location'] = videolocation[sample_id]\n",
    "resultfolder_root = '../../_data/05_tracking_result_projected/step0_attr_prj/'\n",
    "resultfolder = os.path.join(resultfolder_root, result_ls[sample_id])\n",
    "if not os.path.exists(resultfolder):\n",
    "    os.makedirs(resultfolder)\n",
    "traceGDF_keep.drop(\"geometry\", axis = 1).to_csv(os.path.join(resultfolder, sample_id + \".csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3\n",
    "traceGDF_keep['h3_15'] = traceGDF_keep.apply(lambda x: h3.geo_to_h3(x['lat'], x['lon'], 15), axis = 1)\n",
    "traceGDF_agg = traceGDF_keep.groupby('h3_15')['track_id'].nunique().reset_index()\n",
    "traceGDF_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceGDF_agg['geometry'] = traceGDF_agg[f\"h3_15\"].apply(lambda x: Polygon(h3.h3_to_geo_boundary(x)))\n",
    "traceGDF_agg['geometry'] = traceGDF_agg['geometry'].apply(lambda x: Polygon([(i[1], i[0]) for i in list(x.exterior.coords)]))\n",
    "traceGDF_agg = gpd.GeoDataFrame(traceGDF_agg, geometry = traceGDF_agg['geometry'])\n",
    "traceGDF_agg.crs = \"EPSG:4326\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceGDF_agg.plot(figsize = (10,10), column = 'track_id', legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3folder = \"../../_data/05_tracking_result_projected/step5_agg_h3\"\n",
    "traceGDF_agg.to_file(os.path.join(h3folder, sample_id + \".geojson\"), driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_process = [\n",
    "#     'B10_G2_Env2_0001-Scene-004',\n",
    "#  'B10_G2_Env5_0001-Scene-006',\n",
    "#  'B10_G2_Env5_0001-Scene-003',\n",
    "#  'B10_G2_Env1_0001-Scene-002',\n",
    "#  'B16_G8_Env5_0001-Scene-005',\n",
    " 'B16_G8_Env2-Scene-005',\n",
    " 'B16_G8_Env3_0001-Scene-003',\n",
    "#  'B16_G8_Env5_0001-Scene-003',\n",
    " 'B11_G1_Env3_0001-Scene-001',\n",
    " 'B18_G1_Env15_0001-Scene-004',\n",
    " 'B18_G1_Env15_0001-Scene-007'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_name\n",
    "# sample_id = \"B16_G8_Env5_0001-Scene-005\"\n",
    "\n",
    "for sample_id in to_process[1:]:\n",
    "    ref = get_ref(videopath[videopath['video_id']==sample_id]['ref_path'].values[0])\n",
    "    traceGDF_keep = get_proj_video(sample_id, ref, videopath)\n",
    "    traceGDF_keep['location'] = traceGDF_keep['video_id'].apply(lambda x: videolocation[x])\n",
    "    # ref\n",
    "    resultfolder = os.path.join(resultfolder_root, result_ls[sample_id])\n",
    "    traceGDF_keep.drop(\"geometry\", axis = 1).to_csv(os.path.join(resultfolder, sample_id + \".csv\"), index = False)\n",
    "    frame_id = 101\n",
    "    # get_frame_plot(traceGDF_keep, videopath, sample_id, frame_id)\n",
    "    print(\"Done\", sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(resultfolder, sample_id + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = 101\n",
    "sample_id = \"B16_G8_Env5_0001-Scene-005\"\n",
    "get_frame_plot(traceGDF_keep, videopath, sample_id, frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
