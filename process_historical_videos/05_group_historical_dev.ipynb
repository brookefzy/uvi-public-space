{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "from shapely.geometry import Point, Polygon, MultiPoint, LineString\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from itertools import combinations\n",
    "\n",
    "from datetime import datetime, timezone, tzinfo\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from fiona.crs import from_epsg\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import networkx as nx\n",
    "\n",
    "from networkx import edge_betweenness_centrality as betweenness\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "import json\n",
    "\n",
    "font = FontProperties()\n",
    "font.set_family('serif')\n",
    "font.set_name('Times New Roman')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "sns.color_palette(\"hls\", 4)\n",
    "sns.set_context(\"paper\", rc={\"font.size\":10,\"axes.titlesize\":12,\"axes.labelsize\":12})\n",
    "from shapely.geometry import Point\n",
    "globalcrs = \"EPSG:3857\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder_ls = {\n",
    "    \"Bryant Park\":\"bryan_park_1980\",\n",
    "    \"Chestnut Street\":\"chestnut_street_1980\",\n",
    "    \"Downtown Crossing\":\"downtown_crossing_1980\",\n",
    "    \"MET\":\"met_1980\"\n",
    "}\n",
    "\n",
    "# load result path\n",
    "gcloudapi = \"AIzaSyCohhLdvyTC0UsGriQ9j-rU8pRln5wVVG8\"\n",
    "serviceaccount = \"/Users/yuan/Dropbox (Personal)/personal files/ssh/google_drive_personal.json\"\n",
    "import gspread\n",
    "# from oauth2client.service_account import ServiceAccountCredentials\n",
    "gc = gspread.service_account(filename = serviceaccount)\n",
    "\n",
    "\n",
    "def read_url(url, SHEET_NAME):\n",
    "    SHEET_ID = url.split('/')[5]\n",
    "    spreadsheet = gc.open_by_key(SHEET_ID)\n",
    "    worksheet = spreadsheet.worksheet(SHEET_NAME)\n",
    "    rows = worksheet.get_all_records()\n",
    "    df_spread = pd.DataFrame(rows)\n",
    "    return df_spread, worksheet\n",
    "\n",
    "url = \"https://docs.google.com/spreadsheets/d/1djLf9Uhh1zJpPBiSyjTnZ_EkkP1uZf2L8Rg8XWmXKlY/edit?usp=sharing\"\n",
    "SHEETNAME = \"P1_historical_videos\"\n",
    "video_path, other_worksheet = read_url( url, SHEETNAME)\n",
    "\n",
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatecluster(df, dis, epsg):\n",
    "    \"\"\"\n",
    "    This function go through each frame and run DBscan based on different Distance\n",
    "    threshod\n",
    "\n",
    "    \"\"\"\n",
    "    predlist = []\n",
    "    for f in tqdm(df['frame_id'].unique()):\n",
    "        preDF = df[df['frame_id']==f].reset_index(drop = True)\n",
    "        X = preDF[[f\"x_{epsg}\", f\"y_{epsg}\"]].values\n",
    "\n",
    "        # eps : maximum distance between two samples\n",
    "        # Here we use pixel distance for ease of visualization\n",
    "        # 12 pixel for 0.5m, given hunman to human interaction distance maximum as 1.2 meter\n",
    "        # https://en.wikipedia.org/wiki/Proxemics#:~:text=Hall%20described%20the%20interpersonal%20distances,and%20(4)%20public%20space.\n",
    "\n",
    "        clustering = DBSCAN(eps = dis, min_samples = 2).fit(X)\n",
    "        pred = clustering.labels_\n",
    "        predlist.append(pred)\n",
    "    \n",
    "    allpred = np.concatenate(predlist, axis=0)\n",
    "    return allpred\n",
    "\n",
    "def getbasics(file_path):\n",
    "    video = cv2.VideoCapture(file_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('frames per second =',fps)\n",
    "    size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    print('frames size =',size)\n",
    "    # video.release()\n",
    "    return video, fps, size, length\n",
    "\n",
    "def generate_social(traceGDF, epsg, dis = 1.5):\n",
    "    # dislist = [1.5, 2]\n",
    "    # distlistdict = {\n",
    "    #     2263: [1.2, 3.6], # feet\n",
    "    #     3857: [0.6, 1.5] # meter\n",
    "    # }\n",
    "    \"\"\"\n",
    "    d is the distance threshold for DBscan at meter\n",
    "    \"\"\"\n",
    "\n",
    "    clusterlabel = generatecluster(traceGDF, dis, epsg)\n",
    "    FPre = pd.DataFrame(clusterlabel, columns = ['Social'])\n",
    "    DBcluster = pd.concat([traceGDF, FPre], axis = 1)\n",
    "\n",
    "\n",
    "    DBcluster['frame_id'] = DBcluster['frame_id'].astype(int)\n",
    "    # Drop those clusterlabel == -1, create a spatial cluster id\n",
    "    DBcluster['group_id_social'] = DBcluster['frame_id'].astype(str) + '_' +DBcluster['Social'].astype(str)\n",
    "    DBcluster['group_id_social'] = np.where(DBcluster['Social']==-1, np.nan, DBcluster['group_id_social'])\n",
    "    DBSocial = DBcluster[DBcluster['Social']!=-1].reset_index(drop = True)\n",
    "    # os.makedirs(outfolder+\"/step1_dbscan\")\n",
    "    DBSocial['group_id_social'] = DBSocial['group_id_social'].astype(str)\n",
    "    return DBSocial, DBcluster\n",
    "\n",
    "\n",
    "\n",
    "def valid_link(DBSocial, x,y, thred = 0.5, n = 2):\n",
    "    samplegroup = DBSocial[DBSocial['track_id'].isin([x,y])]\n",
    "    # calculate the speed_x, speed_y correlation between track 10 and 11\n",
    "    df_wide = samplegroup.pivot(index = 'frame_id', \n",
    "                                columns = 'track_id', \n",
    "                                values = [f'speed_x_{n}s', \n",
    "                                          f'speed_y_{n}s',\n",
    "                                          f'speed_{n}s']).reset_index()\n",
    "    # calculate the correlation\n",
    "    df_wide = df_wide.dropna()\n",
    "    \n",
    "    coor1 = df_wide[(f\"speed_x_{n}s\",x)].corr(df_wide[(f\"speed_x_{n}s\",y)])\n",
    "    coor2 = df_wide[(f\"speed_y_{n}s\",x)].corr(df_wide[(f\"speed_y_{n}s\",y)])\n",
    "    coor3 = df_wide[(f\"speed_{n}s\",x)].corr(df_wide[(f\"speed_{n}s\",y)])\n",
    "    if coor1>thred and coor2>thred and coor3>thred:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def valid_link_corr(DBSocial, x,y, thred = 0.5, n = 2):\n",
    "    samplegroup = DBSocial[DBSocial['track_id'].isin([x,y])]\n",
    "    # calculate the speed_x, speed_y correlation between track 10 and 11\n",
    "    df_wide = samplegroup.pivot(index = 'frame_id', \n",
    "                                columns = 'track_id', \n",
    "                                values = [f'speed_x_{n}s', \n",
    "                                          f'speed_y_{n}s',\n",
    "                                          f'speed_{n}s']).reset_index()\n",
    "    # calculate the correlation\n",
    "    df_wide = df_wide.dropna()\n",
    "    \n",
    "    coor1 = df_wide[(f\"speed_x_{n}s\",x)].corr(df_wide[(f\"speed_x_{n}s\",y)])\n",
    "    coor2 = df_wide[(f\"speed_y_{n}s\",x)].corr(df_wide[(f\"speed_y_{n}s\",y)])\n",
    "    coor3 = df_wide[(f\"speed_{n}s\",x)].corr(df_wide[(f\"speed_{n}s\",y)])\n",
    "    return coor1, coor2, coor3\n",
    "    \n",
    "\n",
    "def getuvperframe(testdf, iditem):\n",
    "#     testdf = effDF[effDF['frame_id'] == frameid]\n",
    "    U = []\n",
    "    V = []\n",
    "    groupid = []\n",
    "    for i, group in tqdm(testdf.groupby([iditem])['track_id']):\n",
    "\n",
    "    # generate all combinations without replacement \n",
    "    # from the group of similar column pairs\n",
    "        for u, v in itertools.combinations(group, 2):\n",
    "            U.append(u)\n",
    "            V.append(v)\n",
    "            groupid.append(i)\n",
    "            \n",
    "    dfframe = pd.DataFrame({'u':U,\n",
    "             'v':V,\n",
    "              iditem: groupid\n",
    "             })\n",
    "\n",
    "    return dfframe\n",
    "\n",
    "\n",
    "# use girvan_newman for community detection first\n",
    "# df_plot = newlinks.reset_index(drop=True)\n",
    "\n",
    "def most_central_edge(G):\n",
    "    centrality = betweenness(G, weight=\"weight\")\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "\n",
    "def getcommunity(df_links):\n",
    "    G_plot = nx.Graph()\n",
    "    for link in tqdm(df_links.index):\n",
    "        G_plot.add_edge(df_links.iloc[link]['u'],\n",
    "                    df_links.iloc[link]['v'],\n",
    "                    weight = df_links.iloc[link]['weight'])\n",
    "\n",
    "    communities = girvan_newman(G_plot, most_valuable_edge = most_central_edge)\n",
    "    # tuple(sorted(c) for c in next(comp))\n",
    "\n",
    "    node_groups = []\n",
    "    for com in next(communities):\n",
    "        node_groups.append(list(com))\n",
    "    node_groupslen = [len(group) for group in node_groups]\n",
    "    communitydf = pd.DataFrame({\n",
    "    'communityID':np.arange(0, len(node_groupslen)),\n",
    "    'nodegroup':node_groups,\n",
    "    'groupsize':node_groupslen\n",
    "    })\n",
    "    return communitydf\n",
    "\n",
    "def get_confirm_group(communitydf, DB, example_com):\n",
    "    \"\"\"This function only identify the exactly same group, disregarding groups appear across frames.\n",
    "    for example, track 1, 2 in frame 3-8, track 1,2,3 in frame 7-9\n",
    "    \"\"\"\n",
    "    tracks = communitydf[communitydf[\"communityID\"]==example_com][\"nodegroup\"].values[0]\n",
    "    tracks = [int(x) for x in tracks]\n",
    "    tracks.sort()\n",
    "    tracksls = \"_\".join([str(x) for x in tracks])\n",
    "\n",
    "    # for each frame and social id, get a list of tracks\n",
    "    sel = DB[(DB[\"communityID\"]==example_com)&(DB[\"track_id\"].isin(tracks))&(DB[\"Social\"]!=-1)]\n",
    "    frame_summary = sel.groupby([\"frame_id\", \"Social\"])[\"track_id\"].unique().reset_index()\n",
    "    frame_summary[\"track_id_str\"] = frame_summary[\"track_id\"].apply(lambda x: \"_\".join([str(i) for i in x]))\n",
    "    confirmed = frame_summary[frame_summary[\"track_id_str\"]==tracksls]\n",
    "    confirmed[\"communityID\"] = example_com\n",
    "    return confirmed\n",
    "\n",
    "\n",
    "def get_confirm_group_loose(communitydf, DB, example_com):\n",
    "    tracks = communitydf[communitydf[\"communityID\"]==example_com][\"nodegroup\"].values[0]\n",
    "    # tracks = [int(x) for x in tracks]\n",
    "    tracks.sort()\n",
    "    tracksls = \"_\".join([str(x) for x in tracks])\n",
    "\n",
    "    # for each frame and social id, get a list of tracks\n",
    "    sel = DB[(DB[\"communityID\"]==example_com)&(DB[\"track_id\"].isin(tracks))&(DB[\"Social\"]!=-1)]\n",
    "    frame_summary = sel.groupby([\"frame_id\", \"Social\"])[\"track_id\"].unique().reset_index()\n",
    "    frame_summary[\"track_id_str\"] = frame_summary[\"track_id\"].apply(lambda x: \"_\".join([str(i) for i in x]))\n",
    "    frame_summary[\"len\"] = frame_summary[\"track_id\"].apply(lambda x: len(x))\n",
    "    def get_inter(temp):\n",
    "        lst2 = temp[\"track_id_str\"].values[0].split(\"_\")\n",
    "        lst2 = [x for x in temp[\"track_id_str\"].values[0].split(\"_\")]\n",
    "        intersection = [value for value in lst2 if value in tracks]\n",
    "        temp[\"track_ls_intersection\"] = \"_\".join([str(x) for x in intersection])\n",
    "        return temp\n",
    "\n",
    "    reconstruct = frame_summary[frame_summary[\"len\"]>1].groupby(\"track_id_str\").apply(get_inter)\n",
    "    reconstruct[\"communityID\"] = example_com\n",
    "    return reconstruct\n",
    "\n",
    "\n",
    "def get_group(communitydf, DB):\n",
    "    group_df = []\n",
    "    for comID in tqdm(communitydf[\"communityID\"].unique()):\n",
    "        temp = get_confirm_group(communitydf, DB,comID)\n",
    "        group_df.append(temp)\n",
    "\n",
    "    group_df = pd.concat(group_df).reset_index(drop = True)\n",
    "    return group_df\n",
    "\n",
    "def get_group_loose(communitydf, DB):\n",
    "    group_df = []\n",
    "    for comID in tqdm(communitydf[\"communityID\"].unique()):\n",
    "        temp = get_confirm_group_loose(communitydf, DB, comID)\n",
    "        group_df.append(temp)\n",
    "\n",
    "    group_df = pd.concat(group_df).reset_index(drop = True)\n",
    "    return group_df\n",
    "\n",
    "def get_gender_comp(genderls):\n",
    "    if len(genderls)==2:\n",
    "        return \"Mixed\"\n",
    "    else:\n",
    "        return genderls[0]\n",
    "    \n",
    "# load prediction trace\n",
    "def get_pred(video_name):\n",
    "    pred_path = video_path[video_path['video_id'] == video_name]['pred_path'].values[0]\n",
    "\n",
    "    # ref = get_ref(ref_path)\n",
    "    trace = pd.read_csv(pred_path, sep = '\\t', header = None)\n",
    "    trace.columns = [ \"x1\", \"y1\", \"x2\", \"y2\", \"track_id\", \"frame_id\"]\n",
    "    trace['w'] = trace['x2'] - trace['x1']\n",
    "    trace['h'] = trace['y2'] - trace['y1']\n",
    "    trace['ratio'] = trace['w']/trace['h']\n",
    "    # trace.rename(columns = {\"x1\":\"bbox0\", \"y1\":\"bbox1\", \"w\":\"bbox2\", \"h\":\"bbox3\"}, inplace = True)\n",
    "    return trace\n",
    "\n",
    "def compute_color_for_labels(label):\n",
    "    \"\"\"\n",
    "    Simple function that adds fixed color depending on the class\n",
    "    \"\"\"\n",
    "    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "    return tuple(color)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data\n",
    "Current data already contains speed vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# resultfolder_root = \"../../_data/05_tracking_result_projected/step0_attr_prj/\"\n",
    "staginging_folder = \"../../_data/05_tracking_result_projected/step1_speed_vector/historical\"\n",
    "finished = glob.glob(staginging_folder + \"/*_full.csv\")\n",
    "finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_loc = \"Bryant Park\"\n",
    "filepath = os.path.join(staginging_folder, sample_loc+ \"_full.csv\")\n",
    "traceGDF = pd.read_csv(filepath)\n",
    "\n",
    "# note that across video names there are same track_id, so we need to add video name as prefix\n",
    "obs = traceGDF[['track_id','video_id']].drop_duplicates().shape[0]\n",
    "obs_wspeed = traceGDF[['track_id','video_id','speed_0.5s']].dropna(subset=['speed_0.5s']).drop_duplicates(['track_id','video_id']).shape[0]\n",
    "print(f\"Total number of observation in video {sample_loc}: \", obs, \"with speed vector: \", obs_wspeed)\n",
    "\n",
    "# drop the frame_id columns and rename frame_id_new to frame_id\n",
    "traceGDF.rename(columns = {'frame_id':'frame_id_original'}, inplace = True)\n",
    "traceGDF.rename(columns = {'frame_id_new':'frame_id'}, inplace = True)\n",
    "\n",
    "interval = 48 # this represents real world 1 second before sampling. The enlarged video has 480 per second. The video is timeplased 10 times. Therefore 48 frames per real-world second\n",
    "traceGDF['appear_sec'] = traceGDF.groupby(['track_id','video_id'])['frame_id'].transform('count')/interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originsize = traceGDF.shape[0]\n",
    "# # dropping people staying less than 3 seconds, for bryant park, we cannot do this given many people only appeared one time.\n",
    "# # set the threshold to be 0.5 second\n",
    "thred = 0.2*48\n",
    "traceGDF['individual_frame_total'] = traceGDF.groupby(['track_id','video_id'])['frame_id'].transform('nunique')\n",
    "keepGDF = traceGDF[traceGDF['individual_frame_total']>thred].reset_index(drop = True)\n",
    "keepsize = keepGDF.shape[0]\n",
    "per = keepsize/originsize\n",
    "print(\"KEEP {}% of the data\".format(per*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this file is currently too large, filter to every 2 frames\n",
    "thre = 1\n",
    "fps = 479.97\n",
    "fps_adjust = fps/thre\n",
    "traceGDF = keepGDF[keepGDF['frame_id']%thre==0].reset_index(drop = True) # this equals to change the fps to half\n",
    "# traceGDF.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Social Clusters at spatial level\n",
    "One video_id per calculation to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdatafolder =\"../../_data/05_demo/03_group_behavior_sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videols = traceGDF['video_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg = 3857\n",
    "i = 0\n",
    "tracecurrent = traceGDF[traceGDF['video_id']==videols[i]].reset_index(drop = True)\n",
    "DBSocial, DBcluster =  generate_social(tracecurrent, epsg, dis = 1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the spatial group on the ground and image space\n",
    "num_group_frame = DBSocial.groupby(['frame_id', 'frame_id_original'])['group_id_social']\\\n",
    "    .nunique().reset_index().sort_values('group_id_social', ascending = False).reset_index(drop = True)\n",
    "framsel = num_group_frame.at[0, 'frame_id_original']\n",
    "print(\"Selected frame: \", framsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the spatial group on the ground and image space\n",
    "num_group_frame = DBSocial.groupby(['frame_id', 'frame_id_original'])['group_id_social']\\\n",
    "    .nunique().reset_index().sort_values('group_id_social', ascending = False).reset_index(drop = True)\n",
    "framsel = num_group_frame.at[0, 'frame_id_original']\n",
    "print(\"Selected frame: \", framsel)\n",
    "# check frame_id and its immediate next frame_id\n",
    "def get_selfile(framsel, thre=2):\n",
    "\n",
    "    seldb = DBcluster[DBcluster['frame_id_original']==framsel].reset_index(drop = True)\n",
    "    seldb = gpd.GeoDataFrame(seldb, geometry=[Point(x,y) for x,y in zip(seldb['lon'], seldb['lat'])], crs = f\"EPSG:4326\")\n",
    "    ax = seldb[seldb['Social']!=-1].plot(column = 'Social', legend = True, cmap = 'tab20', figsize = (8,8))\n",
    "    seldb[seldb['Social']==-1].plot(color = 'grey', ax = ax)\n",
    "    \n",
    "    seldb_shift = DBcluster[DBcluster['frame_id_original']==framsel+thre*2].reset_index(drop = True)\n",
    "    seldb_shift = gpd.GeoDataFrame(seldb_shift, geometry=[Point(x,y) for x,y in zip(seldb_shift['lon'], \n",
    "                                                                                    seldb_shift['lat'])], \n",
    "                                   crs = f\"EPSG:4326\")\n",
    "    ax = seldb_shift[seldb_shift['Social']!=-1].plot(column = 'Social', legend = True, cmap = 'tab20', figsize = (8,8))\n",
    "    seldb_shift[seldb_shift['Social']==-1].plot(color = 'grey', ax = ax)\n",
    "    return seldb, seldb_shift\n",
    "seldb, seldb_shift = get_selfile(framsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seldb.to_file(os.path.join(vizdatafolder, f\"{sample_loc}_frame{framsel}_social.geojson\"), driver='GeoJSON')\n",
    "seldb_shift.to_file(os.path.join(vizdatafolder, f\"{sample_loc}_frame{framsel+thre*2}_social.geojson\"), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot this frame on the image\n",
    "import cv2\n",
    "i = 0\n",
    "video_name = videols[i]\n",
    "video_file = video_path[video_path['video_id']==video_name]['video_path'].values[0]\n",
    "# load the original trace file\n",
    "trace = get_pred(video_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_plot(trace, seldb, seldb_shift):\n",
    "    data = trace.merge(seldb[[\"track_id_backup\", \"frame_id_original\", 'Social','track_id']], \n",
    "                                               left_on = [\"track_id\", \"frame_id\"],\n",
    "                                               right_on = [\"track_id_backup\", \"frame_id_original\"],\n",
    "                                               suffixes=('', '_new'))\n",
    "    data = data[data['Social']!=-1].reset_index(drop = True)\n",
    "    data_shift = trace.merge(seldb_shift[[\"track_id_backup\", \"frame_id_original\", 'Social','track_id']], \n",
    "                                               left_on = [\"track_id\", \"frame_id\"],\n",
    "                                               right_on = [\"track_id_backup\", \"frame_id_original\"],\n",
    "                                               suffixes=('', '_new'))\n",
    "    data_shift = data_shift[data_shift['Social']!=-1].reset_index(drop = True)\n",
    "    return data, data_shift\n",
    "\n",
    "def plot_img(video_name, framsel, data):\n",
    "    video_file = video_path[video_path['video_id']==video_name]['video_path'].values[0]\n",
    "    \n",
    "    video, fps, size, length= getbasics(video_file)\n",
    "        # set video to the frame\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, framsel)\n",
    "    re, frame = video.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    for j in range(data.shape[0]):\n",
    "        social_id = data.at[j, 'Social']\n",
    "        color = compute_color_for_labels(social_id)\n",
    "        cv2.rectangle(frame,\n",
    "                        (data.at[j,'x1'], \n",
    "                    data.at[j,'y1']), \n",
    "                    (data.at[j,'x2'], \n",
    "                    data.at[j,'y2']), \n",
    "                        color, 2)\n",
    "\n",
    "    fig = plt.subplots(figsize = (10,10))\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    \n",
    "data, data_shift = get_data_for_plot(trace, seldb, seldb_shift)\n",
    "plot_img(video_name, framsel, data)\n",
    "plot_img(video_name, framsel+10, data_shift)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Graph Community\n",
    "## 4.1 Count how many links between two pedestrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkfolder = \"../../_data/05_tracking_result_projected/step2_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two person appear together for at least 1 second (60*2 frame per second )\n",
    "# or half of the appearing time\n",
    "selp = 'social'\n",
    "# selp = 'personal_far'\n",
    "iditem = 'group_id_{}'.format(selp)\n",
    "df_links = getuvperframe(DBSocial, iditem)\n",
    "\n",
    "# First Aggregation, disregard time continuity, only consider frequency\n",
    "df_links = df_links.groupby(['u', 'v']).size().reset_index().rename(columns={0: 'weight'})\n",
    "# df_links['valid'] = df_links.apply(lambda x: valid_link(DBSocial, x['u'], x['v']), \n",
    "#                                    axis = 1)\n",
    "df_links['coor_ls'] = df_links.apply(lambda x: valid_link_corr(DBSocial, x['u'], x['v'], n = 0.5),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 video second 480 frames\n",
    "# 1 video second is 10 second in real life\n",
    "# so 1 real life second is 48 frames\n",
    "# since we only sampled half of the frames\n",
    "# then 1 real life second is 24 links\n",
    "df_links['coor_x'] = df_links['coor_ls'].apply(lambda x: x[0])\n",
    "df_links['coor_y'] = df_links['coor_ls'].apply(lambda x: x[1])\n",
    "df_links['coor_speed'] = df_links['coor_ls'].apply(lambda x: x[2])\n",
    "df_links['valid'] = np.where((df_links['coor_x']>0)&(df_links['coor_y']>0), True, False)\n",
    "df_links.groupby('valid').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links[['u', 'v', 'weight', 'coor_x', 'coor_y', 'coor_speed',\n",
    "       'valid']].to_csv(os.path.join(linkfolder, videols[i] + \"_links.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_links = df_links[df_links['weight'] > timethred*fps].reset_index(drop = True)\n",
    "# at least 0.5 second stay together\n",
    "arbithred = 18 # observe the link frequency distribution, 2 is a good threshold\n",
    "\n",
    "validcondition1 = (df_links['valid']==True)\n",
    "validcondition2 = (df_links['weight'] > arbithred)\n",
    "df_links_valid = df_links[validcondition2].reset_index(drop = True)\n",
    "df_links_valid['u_v'] = df_links_valid.apply(lambda x: \"&&\".join([str(x['u']), str(x['v'])]), axis = 1)\n",
    "df_links_valid['v_u'] = df_links_valid.apply(lambda x: \"&&\".join([str(x['v']), str(x['u'])]), axis = 1)\n",
    "\n",
    "# =========================================================================================\n",
    "# DISREGARDING THE COMMUNITY STEP GIVEN THE DATA SPARSITY\n",
    "# communitydf = getcommunity(df_links_valid)\n",
    "\n",
    "# flatdf = communitydf.explode('nodegroup')\n",
    "# flatdf.rename(columns = {'nodegroup':'track_id'}, inplace = True)\n",
    "\n",
    "# DB = DBcluster.merge(flatdf, on = 'track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links_valid # disregarding time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Replot the valid groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING # here only considers two people in a group. In reality there are large groups\n",
    "arbithred = 18 # observe the link frequency distribution, 2 is a good threshold\n",
    "\n",
    "validcondition1 = (df_links['valid']==True)\n",
    "validcondition2 = (df_links['weight'] > arbithred)\n",
    "df_links_valid = df_links[validcondition2].reset_index(drop = True)\n",
    "df_links_valid['u_v'] = df_links_valid.apply(lambda x: \"&&\".join([str(x['u']), str(x['v'])]), axis = 1)\n",
    "df_links_valid['v_u'] = df_links_valid.apply(lambda x: \"&&\".join([str(x['v']), str(x['u'])]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue varification\n",
    "def get_demolink(data):\n",
    "    \"\"\"HERE THE DATA ONLY CONTAIN ONE FRAME.\"\"\"\n",
    "    data_link = data.groupby('Social')['track_id_new'].unique().reset_index()\n",
    "    data_link['u_v'] = data_link.apply(lambda x: \"&&\".join([str(i) for i in x['track_id_new']]), axis = 1)\n",
    "    demolinks = data_link[(data_link['u_v'].isin(df_links_valid['u_v'].unique()))|(data_link['u_v'].isin(df_links_valid['v_u'].unique()))\n",
    "        ].reset_index(drop = True)\n",
    "    demolinks = demolinks[['Social', 'track_id_new']].explode('track_id_new').reset_index(drop = True)\n",
    "    demolinks['social_track'] = demolinks['Social'].astype(str)+\"$$\"+demolinks['track_id_new'].astype(str)\n",
    "    return demolinks\n",
    "\n",
    "\n",
    "demolinks = get_demolink(data)\n",
    "demolinks_shift = get_demolink(data_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seldb['social_track'] = seldb['Social'].astype(str)+\"$$\"+seldb['track_id'].astype(str)\n",
    "seldb_shift['social_track'] = seldb_shift['Social'].astype(str)+\"$$\"+seldb_shift['track_id'].astype(str)\n",
    "updateseldb = seldb[seldb['social_track'].isin(demolinks['social_track'].unique())]\n",
    "updateseldb_shift = seldb_shift[seldb_shift['social_track'].isin(demolinks_shift['social_track'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_update, data_shift_update = get_data_for_plot(trace, updateseldb, updateseldb_shift)\n",
    "plot_img(video_name, framsel, data_update)\n",
    "plot_img(video_name, framsel+thre*2, data_shift_update)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Continue find all valid groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_link = DBSocial.groupby(['frame_id', 'frame_id_original', 'Social'])['track_id'].unique().reset_index()\n",
    "data_link['group_member'] = data_link.apply(lambda x: \"&&\".join([str(i) for i in x['track_id']]), axis = 1)\n",
    "\n",
    "#measure group length\n",
    "data_link['group_len'] = data_link['track_id'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each group_member, get a list of combination of 2 people\n",
    "testgroupmember = data_link[data_link['group_len']>2].sort_values('group_len', ascending = False).head(10)['u_v'].values[0]\n",
    "testgroupmember = testgroupmember.split(\"&&\")\n",
    "\n",
    "# make a list of all possible combination of 2 people\n",
    "data_link['combination2'] = data_link['track_id'].apply(lambda x: list(combinations(x, 2)))\n",
    "data_link_explode = data_link[['frame_id', 'frame_id_original', 'Social',\n",
    "       'combination2']].explode('combination2').reset_index(drop = True)\n",
    "data_link_explode['u_v'] = data_link_explode['combination2'].apply(lambda x: \"&&\".join([str(i) for i in x]))\n",
    "data_link_explode['v_u'] = data_link_explode['combination2'].apply(lambda x: \"&&\".join([str(i) for i in x[::-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the u_v combination exist in the valid link dataframe\n",
    "demolinks = data_link_explode[(data_link_explode['u_v'].isin(df_links_valid['u_v'].unique()))|(data_link_explode['u_v'].isin(df_links_valid['v_u'].unique()))\n",
    "    ].reset_index(drop = True)\n",
    "demolinks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the u_v combination to group id\n",
    "# noted the u_v and v_u are the same group\n",
    "# allgroups = demolinks['u_v'].unique()\n",
    "# #assign group id to each group\n",
    "# groupdict = {}\n",
    "# for i, group in enumerate(allgroups):\n",
    "#     group_reverse = \"&&\".join(group.split(\"&&\")[::-1])\n",
    "#     if (group not in groupdict.keys())&(group_reverse not in groupdict.keys()):\n",
    "#         groupdict[group] = i\n",
    "#         groupdict[group_reverse] = i\n",
    "# len(groupdict.keys())\n",
    "\n",
    "# demolinks['group_id'] = demolinks['u_v'].apply(lambda x: groupdict[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the groups to each track\n",
    "demolinks = demolinks[['frame_id', \n",
    "                       'frame_id_original', \n",
    "                       'Social', 'combination2']].explode('combination2')\\\n",
    ".reset_index(drop = True).sort_values(['frame_id', 'Social'], ascending=False).rename(columns = {'combination2':'track_id'})\\\n",
    "    .drop_duplicates(['frame_id', 'Social', 'track_id']).reset_index(drop = True)\n",
    "demolinks['frame_social_track'] = demolinks['frame_id'].astype(str)+\"$$\"+\\\n",
    "    demolinks['Social'].astype(str)+\"$$\"+demolinks['track_id'].astype(str)\n",
    "demolinks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the data can be merged back to the original data\n",
    "DBSocial['frame_social_track'] = DBSocial['frame_id'].astype(str)+ \"$$\"\\\n",
    "    + DBSocial['Social'].astype(str)+\"$$\"\\\n",
    "        +DBSocial['track_id'].astype(str)\n",
    "DBSocial_update = DBSocial[DBSocial['frame_social_track'].isin(demolinks['frame_social_track'].unique())]\\\n",
    "    .reset_index(drop = True)\n",
    "DBSocial_update.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBSocial_update.shape[0]/DBcluster.shape[0] # 26% observation ever in a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Social cluster id become the group id within each frame\n",
    "DBSocial_update['group_id_social'] = DBSocial_update['frame_id'].astype(str) + '_' +DBSocial_update['Social'].astype(str)\n",
    "DBSocial_update['group_size'] = DBSocial_update.groupby(['frame_id', 'Social'])['track_id'].transform('nunique')\n",
    "DBSocial_update.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBSocial_update.groupby('group_size')['speed_0.5s'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBcluster.drop('group_id_social', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBcluster['frame_social_track'] = DBcluster['frame_id'].astype(str)+ \"$$\"\\\n",
    "    +DBcluster['Social'].astype(str)+\"$$\"\\\n",
    "        +DBcluster['track_id'].astype(str)\n",
    "DBcluster_update = DBcluster.merge(DBSocial_update[['frame_social_track', 'group_id_social', 'group_size']],\n",
    "                                   on = 'frame_social_track', how = 'left')\n",
    "# merge the DBSocial_update back to the DBcluster\n",
    "DBcluster_update['is_group'] = np.where(DBcluster_update['group_id_social'].isnull(), False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a group is newly formed or not\n",
    "# for each track, find its first frame_id when it is in a group\n",
    "DBcluster_update['group_first_frame'] = DBcluster_update.groupby(['track_id','is_group'])['frame_id'].transform('min')\n",
    "DBcluster_update['group_first_frame'] = np.where(DBcluster_update['is_group']==False, np.nan, DBcluster_update['group_first_frame'])\n",
    "DBcluster_update['track_first_frame'] = DBcluster_update.groupby(['track_id'])['frame_id'].transform('min')\n",
    "DBcluster_update['group_track_delta'] = DBcluster_update['group_first_frame'] - DBcluster_update['track_first_frame']\n",
    "DBcluster_update['group_track_delta'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBcluster_update['emerging_group'] = np.where(DBcluster_update['group_track_delta']>48, True, False) # 1 second\n",
    "DBcluster_update['emerging_group'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBcluster_update.drop('is_new_group', axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBcluster_update.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBcluster_update['group_size'] = DBcluster_update['group_size'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBcluster_update.groupby('group_size')['track_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed tests\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "sns.pointplot(\n",
    "    data = DBcluster_update[DBcluster_update['group_size']<6],\n",
    "    x = \"group_size\",\n",
    "    y = \"speed_0.5s\",\n",
    "    ci = 98,\n",
    "    errwidth = 1,\n",
    "    capsize=.2,\n",
    "    color = \"#3bc0cf\"\n",
    ")\n",
    "ax.set_ylabel(\"Moving Speed (m/s)\")\n",
    "ax.set_xlabel(\"Group Size\")\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed tests\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "sns.pointplot(\n",
    "    data = DBcluster_update,\n",
    "    x = \"is_group\",\n",
    "    y = \"speed_0.5s\",\n",
    "    ci = 98,\n",
    "    errwidth = 1,\n",
    "    capsize=.2,\n",
    "    color = \"#3bc0cf\"\n",
    ")\n",
    "ax.set_ylabel(\"Moving Speed (m/s)\")\n",
    "ax.set_xlabel(\"In Group or Not\")\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data\n",
    "exportfolder = '/Users/yuan/Dropbox (MIT)/whyte_CV/_data/10_clean/03_individual/historical'\n",
    "DBcluster_update.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    'order':\"video order in one location\", \n",
    "     'video_location':\"video location name\", \n",
    "     'track_id':\"reconstructed track id, unique within each video\", \n",
    "       'video_id':\"video id, unique within each location\",\n",
    "       'lat':\"prejected latitude\",\n",
    "       'lon':\"prejected longitude\",\n",
    "       'track_id_backup':\"original track id from the tracking file\", \n",
    "       'speed_0.5s':\"speed in meter per second\",\n",
    "       'speed_x_0.5s':\"speed in meter per second in x direction\", \n",
    "       'speed_y_0.5s':\"speed in meter per second in y direction\", \n",
    "       'hex_id':\"h3 level 15 index\", \n",
    "       'inside':\"inside the comparable area (both historical and current) or not\",\n",
    "        'frame_id':\"reconstructed frame_id, across videos in a location, unique within one location\", \n",
    "        'frame_id_original':\"original frame_id from the tracking file\", \n",
    "        'second_from_start':\"calculated second from start based on the frame_id, 48 frames per real second\",\n",
    "       'appear_sec':\"total second the track appeared in the video\", \n",
    "       'individual_frame_total':\"total number of frames the track appeared in the video\", \n",
    "       'Social':\"spatial cluster id, unique within each frame\", \n",
    "       'frame_social_track':\"frame_id + Social + track_id\",\n",
    "       'group_id_social':\"frame_id + Social, unique within each video\",\n",
    "       'group_size':\"number of tracks in the group\",\n",
    "       'is_group':\"whether the track is in a group or not\",\n",
    "       'group_first_frame':\"first frame_id when the track is in a group\",\n",
    "       'track_first_frame':\"first frame_id when the track appear in this video\", \n",
    "       'group_track_delta':\"difference between group_first_frame and track_first_frame\", \n",
    "       'emerging_group':\"whether the group is newly formed or not\"\n",
    "}\n",
    "DBcluster_update[metadata.keys()].to_csv(os.path.join(exportfolder, sample_loc+\"_\"+ video_name + \"_full.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(metadata, open(os.path.join(exportfolder, \"metadata.json\"), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
